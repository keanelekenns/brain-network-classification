{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dense_subgraph import sdp, qp\n",
    "import numpy as np\n",
    "import json\n",
    "import utils\n",
    "import classification\n",
    "from pipeline import Pipeline\n",
    "from de_transformer import DiscriminativeEdgesTransformer\n",
    "from cs_transformer import ContrastSubgraphTransformer\n",
    "from iidaka_transformer import IidakaTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducible results, set random_state to a number, otherwise set it to None\n",
    "random_state = 42\n",
    "\n",
    "## SELECT CATEGORY ##\n",
    "\n",
    "# DATASET_NAME = \"children\"\n",
    "# DATASET_NAME = \"adolescents\"\n",
    "# DATASET_NAME = \"eyesclosed\"\n",
    "# DATASET_NAME = \"male\"\n",
    "# DATASET_NAME = \"other\"\n",
    "DATASET_NAME = \"all\"\n",
    "\n",
    "\n",
    "## SELECT DATASET PATH ##\n",
    "\n",
    "GRAPH_DIR_PREFIX = \"./data/lanciano_datasets_corr_thresh_80/\"\n",
    "DATA_DESCRIPTOR = \"Lanciano-Processed\"\n",
    "\n",
    "# GRAPH_DIR_PREFIX = \"./data/generated_filt_global/pearson_corr_raw/\"\n",
    "# DATA_DESCRIPTOR = \"Raw-Correlation\"\n",
    "\n",
    "\n",
    "weighted = False\n",
    "if DATA_DESCRIPTOR == \"Raw-Correlation\":\n",
    "    weighted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_GRAPH_DIR = f\"{GRAPH_DIR_PREFIX}{DATASET_NAME}/asd/\"\n",
    "B_GRAPH_DIR = f\"{GRAPH_DIR_PREFIX}{DATASET_NAME}/td/\"\n",
    "a_label=\"ASD\"\n",
    "b_label=\"TD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read brain graph files into numpy arrays\n",
    "\n",
    "if DATASET_NAME == \"all\":\n",
    "    with open(GRAPH_DIR_PREFIX + \"unique.json\", \"r\") as fp:\n",
    "        file_lists = json.load(fp)\n",
    "\n",
    "    graphs_A = np.array([np.loadtxt(filename) for filename in file_lists[a_label]])\n",
    "    graphs_B = np.array([np.loadtxt(filename) for filename in file_lists[b_label]])\n",
    "\n",
    "else:\n",
    "    graphs_A = utils.get_graphs_from_files(A_GRAPH_DIR)\n",
    "    graphs_B = utils.get_graphs_from_files(B_GRAPH_DIR)\n",
    "\n",
    "graphs, labels = utils.label_and_concatenate_graphs(graphs_A=graphs_A, graphs_B=graphs_B, a_label=a_label, b_label=b_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_count = len(graphs_A) if a_label == \"ASD\" else len(graphs_B)\n",
    "td_count = len(graphs_B) if b_label == \"TD\" else len(graphs_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_count, td_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"SVC\": {\"C\": [0.1, 1, 100], \"gamma\": [0.0001, 0.001, 0.01, 0.1]},\n",
    "          \"DiscriminativeEdgesTransformer\": {\n",
    "            \"a_label\": [a_label],\n",
    "            \"b_label\": [b_label],\n",
    "            \"num_edges\": [2, 3, 4, 5, 6],\n",
    "            \"weighted\": [weighted]\n",
    "            }\n",
    "          }\n",
    "\n",
    "pipe = [DiscriminativeEdgesTransformer, StandardScaler, SVC]\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "results, _ = classification.grid_search_cv(X=graphs, y=labels, pipeline_steps=pipe, step_param_grids=p_grid, cv=cv, random_state=random_state)\n",
    "\n",
    "\n",
    "classification.write_results_to_file(filename=f'./outputs/{DATA_DESCRIPTOR}-GridSearchCV-DE-{DATASET_NAME}.txt',\n",
    "                            summary=results[\"summary\"], results=results[\"best_results\"], parameter_grid=p_grid, asd_count=asd_count, td_count=td_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iidaka Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"SVC\": {'C': [0.1, 1, 100], 'gamma': [1e-06, 1e-05, 0.0001]},\n",
    "          \"IidakaTransformer\": {\n",
    "            \"a_label\": [a_label],\n",
    "            \"b_label\": [b_label],\n",
    "            \"effect_size_threshold\": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35]\n",
    "            }\n",
    "          }\n",
    "\n",
    "pipe = [IidakaTransformer, StandardScaler, SVC]\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "results, _ = classification.grid_search_cv(X=graphs, y=labels, pipeline_steps=pipe, step_param_grids=p_grid, cv=cv, random_state=random_state)\n",
    "\n",
    "\n",
    "classification.write_results_to_file(filename=f'./outputs/{DATA_DESCRIPTOR}-GridSearchCV-Iidaka-{DATASET_NAME}.txt',\n",
    "                            summary=results[\"summary\"], results=results[\"best_results\"], parameter_grid=p_grid, asd_count=asd_count, td_count=td_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast Subgraph Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = [ContrastSubgraphTransformer, StandardScaler, SVC]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSP1 QP N3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"SVC\": {\"C\": [100], \"gamma\": [0.1]},\n",
    "          \"ContrastSubgraphTransformer\": {\n",
    "            \"a_label\": [a_label],\n",
    "            \"b_label\": [b_label],\n",
    "            \"alpha\": [None],\n",
    "            \"alpha2\": [None],\n",
    "\n",
    "            # ASD - TD\n",
    "            \"percentile\": [65, 70, 75, 80],\n",
    "            # TD - ASD\n",
    "            \"percentile2\": [65, 70, 75, 95],\n",
    "\n",
    "            \"problem\": [1],\n",
    "            \"solver\": [qp],\n",
    "            \"num_cs\": [3],\n",
    "            }\n",
    "          }\n",
    "\n",
    "results, _ = classification.grid_search_cv(X=graphs, y=labels, pipeline_steps=pipe, step_param_grids=p_grid, cv=cv, random_state=random_state)\n",
    "\n",
    "classification.write_results_to_file(filename=f'./outputs/{DATA_DESCRIPTOR}-GridSearchCV-CSP1-QP-N3-{DATASET_NAME}.txt',\n",
    "                            summary=results[\"summary\"], results=results[\"best_results\"], parameter_grid=p_grid, asd_count=asd_count, td_count=td_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSP2 QP N3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"SVC\": {\"C\": [0.1, 1, 100], \"gamma\": [0.0001, 0.001, 0.1, 1]},\n",
    "          \"ContrastSubgraphTransformer\": {\n",
    "            \"a_label\": [a_label],\n",
    "            \"b_label\": [b_label],\n",
    "            \"alpha\": [None],\n",
    "            \"alpha2\": [None],\n",
    "\n",
    "            \"percentile\": [65, 70, 75, 80, 85, 90, 95],\n",
    "            # TD - ASD\n",
    "            \"percentile2\": [None],\n",
    "\n",
    "            \"problem\": [2],\n",
    "            \"solver\": [qp],\n",
    "            \"num_cs\": [3],\n",
    "            }\n",
    "          }\n",
    "\n",
    "results, _ = classification.grid_search_cv(X=graphs, y=labels, pipeline_steps=pipe, step_param_grids=p_grid, cv=cv, random_state=random_state)\n",
    "\n",
    "classification.write_results_to_file(filename=f'./outputs/{DATA_DESCRIPTOR}-GridSearchCV-CSP2-QP-N3-{DATASET_NAME}.txt',\n",
    "                            summary=results[\"summary\"], results=results[\"best_results\"], parameter_grid=p_grid, asd_count=asd_count, td_count=td_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSP1 SDP N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"SVC\": {\"C\": [100], \"gamma\": [0.1]},\n",
    "          \"ContrastSubgraphTransformer\": {\n",
    "            \"a_label\": [a_label],\n",
    "            \"b_label\": [b_label],\n",
    "            \"alpha\": [None],\n",
    "            \"alpha2\": [None],\n",
    "\n",
    "            # ASD - TD\n",
    "            \"percentile\": [65, 70, 75, 80],\n",
    "            # TD - ASD\n",
    "            \"percentile2\": [65, 70, 75, 95],\n",
    "\n",
    "            \"problem\": [1],\n",
    "            \"solver\": [sdp],\n",
    "            \"num_cs\": [1],\n",
    "            }\n",
    "          }\n",
    "\n",
    "results, _ = classification.grid_search_cv(X=graphs, y=labels, pipeline_steps=pipe, step_param_grids=p_grid, cv=cv, random_state=random_state)\n",
    "\n",
    "classification.write_results_to_file(filename=f'./outputs/{DATA_DESCRIPTOR}-GridSearchCV-CSP1-SDP-N1-{DATASET_NAME}.txt',\n",
    "                            summary=results[\"summary\"], results=results[\"best_results\"], parameter_grid=p_grid, asd_count=asd_count, td_count=td_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSP2 SDP N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"SVC\": {\"C\": [1, 100], \"gamma\": [0.001, 0.1]},\n",
    "          \"ContrastSubgraphTransformer\": {\n",
    "            \"a_label\": [a_label],\n",
    "            \"b_label\": [b_label],\n",
    "            \"alpha\": [None],\n",
    "            \"alpha2\": [None],\n",
    "\n",
    "            \"percentile\": [65, 70, 75, 80, 85, 90, 95],\n",
    "            \"percentile2\": [None],\n",
    "\n",
    "            \"problem\": [2],\n",
    "            \"solver\": [sdp],\n",
    "            \"num_cs\": [1],\n",
    "            }\n",
    "          }\n",
    "\n",
    "results, _ = classification.grid_search_cv(X=graphs, y=labels, pipeline_steps=pipe, step_param_grids=p_grid, cv=cv, random_state=random_state)\n",
    "\n",
    "classification.write_results_to_file(filename=f'./outputs/{DATA_DESCRIPTOR}-GridSearchCV-CSP2-SDP-N1-{DATASET_NAME}.txt',\n",
    "                            summary=results[\"summary\"], results=results[\"best_results\"], parameter_grid=p_grid, asd_count=asd_count, td_count=td_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8346a52b29e2085c7585e978abf79ac58e4d129e03e9060cf63d2201f07da517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
