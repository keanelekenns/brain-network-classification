{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import utils\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducible results, set random_state to a number, otherwise set it to None\n",
    "random_state = 42\n",
    "\n",
    "## SELECT CATEGORY ##\n",
    "\n",
    "# DATASET_NAME = \"children\"\n",
    "# DATASET_NAME = \"adolescents\"\n",
    "# DATASET_NAME = \"eyesclosed\"\n",
    "# DATASET_NAME = \"male\"\n",
    "# DATASET_NAME = \"other\"\n",
    "DATASET_NAME = \"all\"\n",
    "\n",
    "\n",
    "## SELECT DATASET PATH ##\n",
    "\n",
    "# GRAPH_DIR_PREFIX = \"./data/lanciano_datasets_corr_thresh_80/\"\n",
    "# DATA_DESCRIPTOR = \"Lanciano-Processed\"\n",
    "\n",
    "GRAPH_DIR_PREFIX = \"./data/generated_filt_global/pearson_corr_raw/\"\n",
    "DATA_DESCRIPTOR = \"Raw-Correlation\"\n",
    "\n",
    "\n",
    "weighted = False\n",
    "if DATA_DESCRIPTOR == \"Raw-Correlation\":\n",
    "    weighted = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_GRAPH_DIR = f\"{GRAPH_DIR_PREFIX}{DATASET_NAME}/asd/\"\n",
    "B_GRAPH_DIR = f\"{GRAPH_DIR_PREFIX}{DATASET_NAME}/td/\"\n",
    "a_label=\"ASD\"\n",
    "b_label=\"TD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read brain graph files into numpy arrays\n",
    "\n",
    "if DATASET_NAME == \"all\":\n",
    "    with open(GRAPH_DIR_PREFIX + \"unique.json\", \"r\") as fp:\n",
    "        file_lists = json.load(fp)\n",
    "\n",
    "    graphs_A = np.array([np.loadtxt(filename) for filename in file_lists[a_label]])\n",
    "    graphs_B = np.array([np.loadtxt(filename) for filename in file_lists[b_label]])\n",
    "\n",
    "else:\n",
    "    graphs_A = utils.get_graphs_from_files(A_GRAPH_DIR)\n",
    "    graphs_B = utils.get_graphs_from_files(B_GRAPH_DIR)\n",
    "\n",
    "graphs, labels = utils.label_and_concatenate_graphs(graphs_A=graphs_A, graphs_B=graphs_B, a_label=a_label, b_label=b_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edges = 10\n",
    "\n",
    "important_a_edge_matrix = np.zeros_like(graphs[0])\n",
    "important_b_edge_matrix = np.zeros_like(graphs[0])\n",
    "\n",
    "for i in range(10):\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state + i)\n",
    "    for train_index, test_index in folds.split(graphs, labels):\n",
    "        train_graphs = graphs[train_index]\n",
    "        train_labels = labels[train_index]\n",
    "\n",
    "        # This is the algorithm used by DiscriminativeEdgesTransformer in the fit function\n",
    "\n",
    "        # Create and Write Summary Graphs\n",
    "        # Note that (u,v) is the same as (v,u), so we extract the upper triangle of the matrices\n",
    "        summary_A = np.triu(utils.summary_graph(graphs[np.where(labels == a_label)]), k=1)\n",
    "        summary_B = np.triu(utils.summary_graph(graphs[np.where(labels == b_label)]), k=1)\n",
    "            \n",
    "        # Get the difference network between the edge weights in group A and B\n",
    "        diff_net = summary_A - summary_B\n",
    "\n",
    "        # Find the num_edges most positive and most negative edge diffs\n",
    "        partitions = np.argpartition(diff_net, (num_edges, -num_edges), axis=None)\n",
    "        top_n = np.unravel_index(partitions[-num_edges:], diff_net.shape)\n",
    "        bottom_n = np.unravel_index(partitions[:num_edges], diff_net.shape)\n",
    "\n",
    "        # Ensure the top edges are all positive and the bottom edges are all negative\n",
    "        top_edges = diff_net[top_n]\n",
    "        positive = top_edges > 0\n",
    "        positive_indices = (top_n[0][positive], top_n[1][positive])\n",
    "\n",
    "        if len(positive_indices[0]) < num_edges:\n",
    "            print(f\"WARNING: only found {len(positive_indices)} positive DEs (looking for {num_edges}).\")\n",
    "\n",
    "        bottom_edges = diff_net[bottom_n]\n",
    "        negative = bottom_edges < 0\n",
    "        negative_indices = (bottom_n[0][negative], bottom_n[1][negative])\n",
    "\n",
    "        if len(negative_indices[0]) < num_edges:\n",
    "            print(f\"WARNING: only found {len(negative_indices)} negative DEs (looking for {num_edges}).\")\n",
    "\n",
    "        important_a_edge_matrix[positive_indices] += diff_net[positive_indices]\n",
    "        important_b_edge_matrix[negative_indices] += diff_net[negative_indices]\n",
    "\n",
    "np.savetxt(f\"./data/BrainNetViewer/DE_important_{a_label}_edges.edge\", important_a_edge_matrix)\n",
    "np.savetxt(f\"./data/BrainNetViewer/DE_important_{b_label}_edges.edge\", important_b_edge_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8346a52b29e2085c7585e978abf79ac58e4d129e03e9060cf63d2201f07da517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
